{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating stimuli for replication of Saffran et al. 1999\n",
    "\n",
    "The final project for the Research Methods module (ECS719P) is to replicate an experiment from a paper. We decided to replicate the 1st experiment from Saffran et al. 1999 (\"Statistical learning of tone sequences by human infants and adults\"). This notebook generates the stimuli for the experiment.\n",
    "\n",
    "## The stimuli\n",
    "\n",
    "The paper uses eleven 0.33 second pure tones within an (almost) chromatic scale starting at middle C (A# was skipped). These are the \"sylables\". For each of 2 languages 6 \"tone words\" are created, each one from 3 syllables. 6 sentences are composed from 18 words each. These are concatenated to create 7 minute \"tone story\" for each language. Note that there is no mark for word / sentence boundary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues\n",
    "\n",
    "- The paper uses 11 tones, but they are not 11 chromatic tones starting from middle C, the note A# was skipped.\n",
    "- The way sentences are composed is unclear. We concluded that each word is presented 3 times in a sentence (with no consecutive pairs), but it is not obvious from the text.\n",
    "- Should we add a short fade in and fade out for each note to eliminate the clicking sound? Currently there are no fades.\n",
    "- There are two randomizations of the test trials. It is unclear if everything should be randomized (both order of trials and order of pairs) or only the order of the trials. Current the trials are fully randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import functools\n",
    "import os\n",
    "import random\n",
    "\n",
    "import soundfile as sf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General preperation for current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run: 2017_01_21__15_09_56\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_BASE_DIR = 'output'\n",
    "LOG_FILE = 'log.txt'\n",
    "\n",
    "run = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "print(f'Current run: {run}')\n",
    "\n",
    "if not os.path.exists(OUTPUT_BASE_DIR):\n",
    "    os.mkdir(OUTPUT_BASE_DIR)\n",
    "output_dir = os.path.join(OUTPUT_BASE_DIR, run)\n",
    "os.mkdir(output_dir)\n",
    "\n",
    "python_print = print\n",
    "\n",
    "\n",
    "def print(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Both print and write everything to log file.\n",
    "    \"\"\"\n",
    "    python_print(*args, **kwargs)\n",
    "    # Open in 'append' mode\n",
    "    with open(os.path.join(output_dir, LOG_FILE), 'a') as f:\n",
    "        kwargs['file'] = f\n",
    "        python_print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic data generation\n",
    "\n",
    "Most of the work will involve symbolic representation of the materials. The tones will be marked with numbers (0 to 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to print notes, words, sentences, and stories\n",
    "\n",
    "def note_text(note):\n",
    "    texts = [\n",
    "        'C',\n",
    "        'C#',\n",
    "        'D',\n",
    "        'D#',\n",
    "        'E',\n",
    "        'F',\n",
    "        'F#',\n",
    "        'G',\n",
    "        'G#',\n",
    "        'A',\n",
    "        'B',  # Notice that A# is skipped\n",
    "    ]\n",
    "    return texts[note]\n",
    "\n",
    "\n",
    "def word_text(word):\n",
    "    return ''.join(note_text(note) for note in word)\n",
    "\n",
    "\n",
    "def sentence_text(sentence):\n",
    "    return ' '.join(word_text(word) for word in sentence)\n",
    "\n",
    "\n",
    "def story_text(story):\n",
    "    return ' | '.join(sentence_text(sentence) for sentence in story)\n",
    "\n",
    "\n",
    "# Other utilities\n",
    "\n",
    "def contains_consecutive_pairs(iterable):\n",
    "    for x, y in zip(iterable, iterable[1:]):\n",
    "        if x == y:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "assert not contains_consecutive_pairs([1, 2, 3, 4])\n",
    "assert not contains_consecutive_pairs([])\n",
    "assert contains_consecutive_pairs([1, 2, 2, 3, 4])\n",
    "\n",
    "\n",
    "def flatten(iterable):\n",
    "    for item in iterable:\n",
    "        if isinstance(item, Iterable):\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item\n",
    "            \n",
    "            \n",
    "assert list(flatten([1, [2, [3, 4]]])) == [1, 2, 3, 4]\n",
    "assert list(flatten([1, [2, 3], [4, 5]])) == [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a symbolic \"tone story\"\n",
    "\n",
    "The `languages` list holds the entire data structure for words, sentences, and stories for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language 1 words: ADB DFE GG#A FCF# D#ED CC#D\n",
      "language 2 words: AC#E F#G#E GCD# C#BA C#FD G#BA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "languages = [\n",
    "    {\n",
    "        'num': 1,\n",
    "        'words': [\n",
    "            (9, 2, 10),\n",
    "            (2, 5, 4),\n",
    "            (7, 8, 9),\n",
    "            (5, 0, 6),\n",
    "            (3, 4, 2),\n",
    "            (0, 1, 2),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'num': 2,\n",
    "        'words': [\n",
    "            (9, 1, 4),\n",
    "            (6, 8, 4),\n",
    "            (7, 0, 3),\n",
    "            (1, 10, 9),\n",
    "            (1, 5, 2),\n",
    "            (8, 10, 9),\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sanity check that the words are correct\n",
    "# Compare the output to the paper\n",
    "for language in languages:\n",
    "    print(f\"language {language['num']} words:\", end=' ')\n",
    "    print(sentence_text(language['words']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_sentence(words):\n",
    "    # Generate sentences until there are no consecutive words\n",
    "    while True:\n",
    "        sentence = words * 3\n",
    "        random.shuffle(sentence)\n",
    "        if not contains_consecutive_pairs(sentence):\n",
    "            return sentence\n",
    "\n",
    "\n",
    "for language in languages:\n",
    "    # 6 sentences per language\n",
    "    language['sentences'] = [create_sentence(language['words']) for _ in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    # 24 sentences in a story\n",
    "    language['story'] = random.choices(language['sentences'], k=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating symbolic trials (and practice trials)\n",
    "\n",
    "Each participants hear 36 trials, each one contains a word the participant is familiar with and a word from the opposite language. The participant than mark (on paper) which word was more familiar. There are two randomized versions of the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_random_trials(languages):\n",
    "    languages_words = [l['words'] for l in languages]\n",
    "    trials = list(itertools.product(*languages_words))\n",
    "    random.shuffle(trials)\n",
    "    for trial in trials:\n",
    "        trial = list(trial)\n",
    "        random.shuffle(trial)\n",
    "        yield trial\n",
    "        \n",
    "# Two randomized trials\n",
    "trials = [list(generate_random_trials(languages)) for _ in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"All subjects heard three practice trials prior to testing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice_trials = list(itertools.islice(generate_random_trials(languages), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'languages': languages,\n",
    "    'trials': trials,\n",
    "    'practice_trials': practice_trials,\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'data.json'), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the transition probabilities matrix and from that languages and words stats\n",
    "\n",
    "The generated data structures are not modified here. All of the code below only analyse the generated data and spits out some stats that were used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language 1 probabilities\n",
      "------------------------\n",
      "within words: min 0.250; max 1.000; mean 0.652\n",
      "between words: min 0.000; max 0.319; mean 0.029\n",
      "words transitional probabilities (averaged over the two within word transitions)\n",
      "- ADB: 0.476\n",
      "- DFE: 0.434\n",
      "- GG#A: 1.000\n",
      "- FCF#: 0.500\n",
      "- D#ED: 0.753\n",
      "- CC#D: 0.750\n",
      "\n",
      "language 2 probabilities\n",
      "------------------------\n",
      "within words: min 0.333; max 1.000; mean 0.679\n",
      "between words: min 0.000; max 0.458; mean 0.032\n",
      "words transitional probabilities (averaged over the two within word transitions)\n",
      "- AC#E: 0.404\n",
      "- F#G#E: 0.750\n",
      "- GCD#: 1.000\n",
      "- C#BA: 0.667\n",
      "- C#FD: 0.667\n",
      "- G#BA: 0.750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_transitional_probabilities(story):\n",
    "    \"\"\"\n",
    "    Calculate a 11 * 11 matrix of transitional probabilities in the \"tone story\".\n",
    "    Cell [i, j] in the matrix is the probability of transitioning to note j after\n",
    "    note i.\n",
    "    \"\"\"\n",
    "    frequency_matrix = np.zeros((11, 11))\n",
    "    flat_story = list(flatten(story))\n",
    "    for x, y in zip(flat_story, flat_story[1:]):\n",
    "        frequency_matrix[x, y] += 1\n",
    "    # Normalized rows\n",
    "    trans_probs = frequency_matrix / frequency_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    return np.nan_to_num(trans_probs)\n",
    "\n",
    "\n",
    "def calculate_within_words_mask(words):\n",
    "    \"\"\"\n",
    "    Calculate a 11 * 11 mask matrix (elements are either 0 or 1) that mark the\n",
    "    within words transitions. AKA, if a transition from i to j is presented in a\n",
    "    word then the matrix [i, j] value is 1, otherwise it's 0.\n",
    "    \"\"\"\n",
    "    within_words_mask = np.zeros((11, 11))\n",
    "    for word in words:\n",
    "        within_words_mask[word[0], word[1]] = 1\n",
    "        within_words_mask[word[1], word[2]] = 1       \n",
    "    return within_words_mask\n",
    "\n",
    "\n",
    "def word_transitional_probabilities(word, trans_prob):\n",
    "    \"\"\"\n",
    "    Calculate the average transitional probabilities of a word.\n",
    "    \"\"\"\n",
    "    return (trans_probs[word[0], word[1]] + trans_probs[word[1], word[2]]) / 2\n",
    "\n",
    "\n",
    "for language in languages:\n",
    "    trans_probs = calculate_transitional_probabilities(language['story'])\n",
    "    within_words_mask = calculate_within_words_mask(language['words'])\n",
    "\n",
    "    # Printing the results\n",
    "    header = f\"language {language['num']} probabilities\"\n",
    "    print(header)\n",
    "    print('-' * len(header))\n",
    "\n",
    "    for name, is_within in [('within', 1), ('between', 0)]:\n",
    "        values = trans_probs[within_words_mask == is_within]\n",
    "        print(f'{name} words: min {min(values):.3f}; max {max(values):.3f}; mean {np.mean(values):.3f}')\n",
    "    \n",
    "    print('words transitional probabilities (averaged over the two within word transitions)')\n",
    "    for word in language['words']:\n",
    "        print(f'- {word_text(word)}: {word_transitional_probabilities(word, trans_probs):.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio utility functions\n",
    "\n",
    "Note frequencies are copied from PureData `mtof` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "AMPLITUDE = 0.8  # Just be on the safe side...\n",
    "\n",
    "\n",
    "def note_freq(note):\n",
    "    freqs = [\n",
    "        261.6,  # middle C\n",
    "        277.1,\n",
    "        293.6,\n",
    "        311.1,\n",
    "        329.6,\n",
    "        349.2,\n",
    "        369.9,\n",
    "        391.9,\n",
    "        415.3,\n",
    "        440,  # A\n",
    "        493.8,  # B, notice that A# was skipped\n",
    "    ]\n",
    "    return freqs[note]\n",
    "\n",
    "\n",
    "# Sanity check that A is indeed 440\n",
    "assert(note_text(9) == 'A')\n",
    "assert(note_freq(9) == 440)\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=11)\n",
    "def note_audio(note):\n",
    "    \"\"\"\n",
    "    Generating an array of 0.33 second of that note.\n",
    "    \"\"\"\n",
    "    length_in_samples = int(SAMPLE_RATE * 0.33)\n",
    "    freq = note_freq(note)\n",
    "    x = np.arange(length_in_samples)\n",
    "    fade_samples = int(0.01 * SAMPLE_RATE)\n",
    "    envelope = np.concatenate([\n",
    "        np.linspace(0, 1, fade_samples),\n",
    "        np.ones(length_in_samples - 2 * fade_samples),\n",
    "        np.linspace(1, 0, fade_samples),\n",
    "    ])\n",
    "    return AMPLITUDE * envelope * np.sin(2 * np.pi * freq * x / SAMPLE_RATE)\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=2)\n",
    "def silence(length_in_seconds):\n",
    "    return np.zeros(int(length_in_seconds * SAMPLE_RATE))\n",
    "\n",
    "\n",
    "def word_audio(word):\n",
    "    return np.concatenate([note_audio(note) for note in word])\n",
    "\n",
    "\n",
    "def trial_audio(trial):\n",
    "    word_a, word_b = trial\n",
    "    return np.concatenate([\n",
    "        word_audio(word_a),\n",
    "        silence(0.75),\n",
    "        word_audio(word_b),\n",
    "        silence(5),\n",
    "    ])\n",
    "\n",
    "\n",
    "def trials_audio(trials):\n",
    "    return np.concatenate([trial_audio(trial) for trial in trials])\n",
    "\n",
    "\n",
    "def export(filename, audio):\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    sf.write(filepath, audio, SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 377 ms, sys: 203 ms, total: 580 ms\n",
      "Wall time: 795 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for language in languages:\n",
    "    flat_story = flatten(language['story'])\n",
    "    audio_story = np.concatenate([note_audio(note) for note in flat_story])\n",
    "    export(f\"language_{language['num']}_story.wav\", audio_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate trials\n",
    "\n",
    "There are 0.75 seconds silence between the words and 5 seconds between trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 263 ms, sys: 287 ms, total: 550 ms\n",
      "Wall time: 694 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "export('trials_a.wav', trials_audio(trials[0]))\n",
    "export('trials_b.wav', trials_audio(trials[1]))\n",
    "export('practice_trials.wav', trials_audio(practice_trials))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
